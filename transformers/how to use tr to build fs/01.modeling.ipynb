{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use Transformer Networks to build a Forecasting model: modeling\n",
    "- https://towardsdatascience.com/how-to-use-transformer-networks-to-build-a-forecasting-model-297f9270e630"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <b>Author : Kwang Myung Yu</b></div>\n",
    "<div style=\"text-align: right\"> Initial upload: 2023.11.06</div>\n",
    "<div style=\"text-align: right\"> Last update: 2023.11.06</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "# print(plt.stype.available)\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from model import TimeSeriesForcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 100\n",
    "\n",
    "source = torch.rand(size=(32, 16, 9))\n",
    "target_in = torch.rand(size=(32, 16, 8))\n",
    "target_out = torch.rand(size=(32, 16, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TimeSeriesForcasting(n_encoder_inputs=9, n_decoder_inputs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesForcasting(\n",
       "  (input_pos_embedding): Embedding(1024, 512)\n",
       "  (target_pos_embedding): Embedding(1024, 512)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (input_projection): Linear(in_features=9, out_features=512, bias=True)\n",
       "  (output_projection): Linear(in_features=8, out_features=512, bias=True)\n",
       "  (linear): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (do): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torchinfo/torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m--> 295\u001b[0m     _ \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49mx, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    296\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1569\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/Desktop/project/timeseries-study/transformers/how to use tr to build fs/model.py:110\u001b[0m, in \u001b[0;36mTimeSeriesForcasting.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 110\u001b[0m     src, trg \u001b[39m=\u001b[39m x\n\u001b[1;32m    112\u001b[0m     src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_src(src)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/sguys99/Desktop/project/timeseries-study/transformers/how to use tr to build fs/01.modeling.ipynb ì…€ 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sguys99/Desktop/project/timeseries-study/transformers/how%20to%20use%20tr%20to%20build%20fs/01.modeling.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m summary(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sguys99/Desktop/project/timeseries-study/transformers/how%20to%20use%20tr%20to%20build%20fs/01.modeling.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     ts,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sguys99/Desktop/project/timeseries-study/transformers/how%20to%20use%20tr%20to%20build%20fs/01.modeling.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     [(\u001b[39m32\u001b[39;49m, \u001b[39m16\u001b[39;49m, \u001b[39m9\u001b[39;49m)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sguys99/Desktop/project/timeseries-study/transformers/how%20to%20use%20tr%20to%20build%20fs/01.modeling.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torchinfo/torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m validate_user_params(\n\u001b[1;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m x, correct_input_size \u001b[39m=\u001b[39m process_input(\n\u001b[1;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m summary_list \u001b[39m=\u001b[39m forward_pass(\n\u001b[1;32m    224\u001b[0m     model, x, batch_dim, cache_forward_pass, device, model_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m formatting \u001b[39m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    227\u001b[0m results \u001b[39m=\u001b[39m ModelStatistics(\n\u001b[1;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    229\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torchinfo/torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    303\u001b[0m     executed_layers \u001b[39m=\u001b[39m [layer \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m summary_list \u001b[39mif\u001b[39;00m layer\u001b[39m.\u001b[39mexecuted]\n\u001b[0;32m--> 304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecuted layers up to: \u001b[39m\u001b[39m{\u001b[39;00mexecuted_layers\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[39mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "summary(\n",
    "    ts,\n",
    "    [(32, 16, 9)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë‹¤ì‹œ í•´ë³¼ê²ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ts((source, target_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5907],\n",
       "         [0.4749],\n",
       "         [0.4568],\n",
       "         [0.6665],\n",
       "         [0.6275],\n",
       "         [0.5371],\n",
       "         [0.3372],\n",
       "         [0.7560],\n",
       "         [0.5143],\n",
       "         [0.5523],\n",
       "         [0.3809],\n",
       "         [0.9313],\n",
       "         [0.7591],\n",
       "         [0.7419],\n",
       "         [0.5821],\n",
       "         [0.6229]],\n",
       "\n",
       "        [[0.5057],\n",
       "         [0.5727],\n",
       "         [0.2449],\n",
       "         [0.4390],\n",
       "         [0.5926],\n",
       "         [0.2189],\n",
       "         [0.6262],\n",
       "         [0.5845],\n",
       "         [0.4180],\n",
       "         [0.7505],\n",
       "         [0.5109],\n",
       "         [0.5675],\n",
       "         [0.3190],\n",
       "         [0.6594],\n",
       "         [0.4584],\n",
       "         [0.5172]],\n",
       "\n",
       "        [[0.8649],\n",
       "         [0.9276],\n",
       "         [0.7171],\n",
       "         [0.9946],\n",
       "         [1.4224],\n",
       "         [0.6785],\n",
       "         [0.6954],\n",
       "         [1.0875],\n",
       "         [0.4768],\n",
       "         [0.5934],\n",
       "         [0.7706],\n",
       "         [0.6452],\n",
       "         [0.6352],\n",
       "         [0.7595],\n",
       "         [0.9154],\n",
       "         [0.6167]],\n",
       "\n",
       "        [[0.8569],\n",
       "         [0.7168],\n",
       "         [0.5801],\n",
       "         [0.4995],\n",
       "         [0.7678],\n",
       "         [0.5392],\n",
       "         [0.3535],\n",
       "         [0.3164],\n",
       "         [0.4415],\n",
       "         [0.7892],\n",
       "         [0.5925],\n",
       "         [0.5020],\n",
       "         [0.1383],\n",
       "         [0.8129],\n",
       "         [0.5949],\n",
       "         [0.6748]],\n",
       "\n",
       "        [[0.7507],\n",
       "         [0.7293],\n",
       "         [0.6660],\n",
       "         [0.7251],\n",
       "         [0.5808],\n",
       "         [0.3978],\n",
       "         [0.6497],\n",
       "         [0.8132],\n",
       "         [0.3517],\n",
       "         [0.7562],\n",
       "         [0.3867],\n",
       "         [0.7405],\n",
       "         [0.9948],\n",
       "         [0.6835],\n",
       "         [0.7302],\n",
       "         [0.7343]],\n",
       "\n",
       "        [[0.2993],\n",
       "         [0.4616],\n",
       "         [0.3881],\n",
       "         [0.5886],\n",
       "         [0.5889],\n",
       "         [0.7614],\n",
       "         [0.6149],\n",
       "         [0.4735],\n",
       "         [0.4106],\n",
       "         [0.3449],\n",
       "         [0.3773],\n",
       "         [0.7332],\n",
       "         [0.6071],\n",
       "         [0.4690],\n",
       "         [0.4155],\n",
       "         [1.0016]],\n",
       "\n",
       "        [[0.5899],\n",
       "         [0.5147],\n",
       "         [0.7618],\n",
       "         [0.6940],\n",
       "         [0.5624],\n",
       "         [0.5415],\n",
       "         [0.4227],\n",
       "         [0.9381],\n",
       "         [0.4225],\n",
       "         [0.5715],\n",
       "         [0.5869],\n",
       "         [0.7391],\n",
       "         [0.6574],\n",
       "         [0.6221],\n",
       "         [0.7586],\n",
       "         [0.7276]],\n",
       "\n",
       "        [[0.3512],\n",
       "         [0.5498],\n",
       "         [0.2636],\n",
       "         [0.4644],\n",
       "         [0.6231],\n",
       "         [0.4429],\n",
       "         [0.4593],\n",
       "         [0.6235],\n",
       "         [0.6359],\n",
       "         [0.6914],\n",
       "         [0.6712],\n",
       "         [0.5343],\n",
       "         [0.8362],\n",
       "         [0.7893],\n",
       "         [0.4189],\n",
       "         [0.6393]],\n",
       "\n",
       "        [[0.3127],\n",
       "         [0.6212],\n",
       "         [0.6984],\n",
       "         [0.3714],\n",
       "         [0.8394],\n",
       "         [0.7465],\n",
       "         [0.4348],\n",
       "         [0.6173],\n",
       "         [0.6993],\n",
       "         [0.4371],\n",
       "         [1.0511],\n",
       "         [1.0290],\n",
       "         [0.6202],\n",
       "         [0.6114],\n",
       "         [0.6656],\n",
       "         [0.6288]],\n",
       "\n",
       "        [[0.4831],\n",
       "         [0.3239],\n",
       "         [0.8509],\n",
       "         [0.4826],\n",
       "         [0.8234],\n",
       "         [0.3887],\n",
       "         [0.6887],\n",
       "         [0.5810],\n",
       "         [0.8619],\n",
       "         [0.8341],\n",
       "         [0.7241],\n",
       "         [0.7827],\n",
       "         [0.6815],\n",
       "         [0.7456],\n",
       "         [0.7804],\n",
       "         [0.9088]],\n",
       "\n",
       "        [[0.6596],\n",
       "         [0.8363],\n",
       "         [0.4057],\n",
       "         [0.7629],\n",
       "         [0.6703],\n",
       "         [0.9520],\n",
       "         [0.8819],\n",
       "         [0.8141],\n",
       "         [0.7051],\n",
       "         [1.0503],\n",
       "         [0.5475],\n",
       "         [0.7544],\n",
       "         [0.6831],\n",
       "         [0.9068],\n",
       "         [0.9997],\n",
       "         [0.9029]],\n",
       "\n",
       "        [[1.2129],\n",
       "         [0.6927],\n",
       "         [0.2403],\n",
       "         [0.4012],\n",
       "         [0.8582],\n",
       "         [0.8830],\n",
       "         [0.5852],\n",
       "         [0.7392],\n",
       "         [0.4726],\n",
       "         [0.9419],\n",
       "         [0.8892],\n",
       "         [0.8133],\n",
       "         [0.9336],\n",
       "         [0.8416],\n",
       "         [0.7670],\n",
       "         [0.8031]],\n",
       "\n",
       "        [[0.5656],\n",
       "         [0.6028],\n",
       "         [0.6703],\n",
       "         [0.4141],\n",
       "         [0.8742],\n",
       "         [0.5319],\n",
       "         [0.3878],\n",
       "         [0.6879],\n",
       "         [0.7220],\n",
       "         [0.5065],\n",
       "         [0.6707],\n",
       "         [1.0495],\n",
       "         [0.4233],\n",
       "         [0.7254],\n",
       "         [0.6551],\n",
       "         [0.6048]],\n",
       "\n",
       "        [[0.5847],\n",
       "         [0.6149],\n",
       "         [0.5468],\n",
       "         [0.7580],\n",
       "         [0.4793],\n",
       "         [0.6082],\n",
       "         [0.3133],\n",
       "         [0.5492],\n",
       "         [0.5461],\n",
       "         [0.5834],\n",
       "         [0.6118],\n",
       "         [0.6699],\n",
       "         [0.5278],\n",
       "         [0.4390],\n",
       "         [0.6306],\n",
       "         [0.5480]],\n",
       "\n",
       "        [[0.3576],\n",
       "         [0.2688],\n",
       "         [0.0100],\n",
       "         [0.5630],\n",
       "         [0.6138],\n",
       "         [0.4261],\n",
       "         [0.4406],\n",
       "         [0.6858],\n",
       "         [0.3520],\n",
       "         [0.5733],\n",
       "         [0.6141],\n",
       "         [0.6484],\n",
       "         [0.1358],\n",
       "         [0.4900],\n",
       "         [0.5470],\n",
       "         [0.2611]],\n",
       "\n",
       "        [[0.4110],\n",
       "         [0.3120],\n",
       "         [0.3772],\n",
       "         [0.5211],\n",
       "         [0.6408],\n",
       "         [0.6702],\n",
       "         [0.6287],\n",
       "         [0.5201],\n",
       "         [0.7026],\n",
       "         [0.4368],\n",
       "         [0.6769],\n",
       "         [0.2201],\n",
       "         [0.5216],\n",
       "         [0.8070],\n",
       "         [0.7311],\n",
       "         [0.5638]],\n",
       "\n",
       "        [[0.6496],\n",
       "         [0.8321],\n",
       "         [0.6602],\n",
       "         [0.7913],\n",
       "         [0.8655],\n",
       "         [0.5457],\n",
       "         [0.5695],\n",
       "         [0.6928],\n",
       "         [0.4032],\n",
       "         [0.6338],\n",
       "         [0.5535],\n",
       "         [0.8994],\n",
       "         [0.7554],\n",
       "         [0.6196],\n",
       "         [0.7655],\n",
       "         [0.6329]],\n",
       "\n",
       "        [[0.4828],\n",
       "         [0.2957],\n",
       "         [0.6813],\n",
       "         [0.6916],\n",
       "         [0.6518],\n",
       "         [0.6502],\n",
       "         [0.6891],\n",
       "         [0.8301],\n",
       "         [0.4113],\n",
       "         [0.6714],\n",
       "         [0.5192],\n",
       "         [0.5714],\n",
       "         [0.5355],\n",
       "         [0.6932],\n",
       "         [0.6226],\n",
       "         [0.4550]],\n",
       "\n",
       "        [[0.4285],\n",
       "         [0.2985],\n",
       "         [0.4583],\n",
       "         [0.4826],\n",
       "         [0.5582],\n",
       "         [0.3144],\n",
       "         [0.3999],\n",
       "         [0.8887],\n",
       "         [0.4612],\n",
       "         [0.4280],\n",
       "         [0.7817],\n",
       "         [0.5824],\n",
       "         [0.2570],\n",
       "         [0.7160],\n",
       "         [0.9357],\n",
       "         [0.5853]],\n",
       "\n",
       "        [[0.6790],\n",
       "         [0.3317],\n",
       "         [0.4865],\n",
       "         [0.5618],\n",
       "         [0.1562],\n",
       "         [0.3970],\n",
       "         [0.2701],\n",
       "         [0.6579],\n",
       "         [0.3133],\n",
       "         [0.7398],\n",
       "         [0.4022],\n",
       "         [0.3970],\n",
       "         [0.3413],\n",
       "         [0.4609],\n",
       "         [0.3150],\n",
       "         [0.5107]],\n",
       "\n",
       "        [[0.3293],\n",
       "         [0.6080],\n",
       "         [0.6414],\n",
       "         [0.5128],\n",
       "         [0.6794],\n",
       "         [0.5839],\n",
       "         [0.5150],\n",
       "         [0.4788],\n",
       "         [0.2744],\n",
       "         [0.7035],\n",
       "         [0.7610],\n",
       "         [0.5332],\n",
       "         [0.7544],\n",
       "         [0.5834],\n",
       "         [0.6935],\n",
       "         [0.5658]],\n",
       "\n",
       "        [[0.2612],\n",
       "         [0.2564],\n",
       "         [0.2787],\n",
       "         [0.6420],\n",
       "         [0.5694],\n",
       "         [0.6342],\n",
       "         [0.4419],\n",
       "         [1.1189],\n",
       "         [0.3570],\n",
       "         [0.5355],\n",
       "         [0.5101],\n",
       "         [0.4581],\n",
       "         [0.8541],\n",
       "         [0.6600],\n",
       "         [0.4492],\n",
       "         [0.3588]],\n",
       "\n",
       "        [[0.3996],\n",
       "         [0.5809],\n",
       "         [0.3944],\n",
       "         [0.4438],\n",
       "         [0.6844],\n",
       "         [0.6492],\n",
       "         [0.2804],\n",
       "         [0.6027],\n",
       "         [0.8776],\n",
       "         [0.5134],\n",
       "         [0.6739],\n",
       "         [0.5892],\n",
       "         [0.6303],\n",
       "         [0.6039],\n",
       "         [0.6956],\n",
       "         [0.8565]],\n",
       "\n",
       "        [[0.7647],\n",
       "         [0.5272],\n",
       "         [0.2860],\n",
       "         [0.5462],\n",
       "         [0.7995],\n",
       "         [0.5570],\n",
       "         [0.4021],\n",
       "         [0.6735],\n",
       "         [0.3606],\n",
       "         [0.6307],\n",
       "         [0.6941],\n",
       "         [0.8031],\n",
       "         [0.8119],\n",
       "         [0.5618],\n",
       "         [0.6169],\n",
       "         [0.7271]],\n",
       "\n",
       "        [[0.4429],\n",
       "         [0.8325],\n",
       "         [0.6773],\n",
       "         [0.8760],\n",
       "         [0.7007],\n",
       "         [0.6944],\n",
       "         [0.6683],\n",
       "         [0.8108],\n",
       "         [0.8104],\n",
       "         [0.5903],\n",
       "         [0.5808],\n",
       "         [0.6527],\n",
       "         [0.5501],\n",
       "         [0.7715],\n",
       "         [0.6606],\n",
       "         [0.5745]],\n",
       "\n",
       "        [[0.3580],\n",
       "         [0.4840],\n",
       "         [0.6400],\n",
       "         [0.4704],\n",
       "         [0.7610],\n",
       "         [0.3737],\n",
       "         [0.3675],\n",
       "         [0.7608],\n",
       "         [0.4194],\n",
       "         [0.3957],\n",
       "         [0.5064],\n",
       "         [0.4433],\n",
       "         [0.5360],\n",
       "         [0.7484],\n",
       "         [0.6634],\n",
       "         [0.5649]],\n",
       "\n",
       "        [[0.8986],\n",
       "         [0.4594],\n",
       "         [0.4419],\n",
       "         [0.3743],\n",
       "         [0.7364],\n",
       "         [0.5742],\n",
       "         [0.1914],\n",
       "         [0.6998],\n",
       "         [0.3724],\n",
       "         [0.5594],\n",
       "         [0.3961],\n",
       "         [0.6590],\n",
       "         [0.3596],\n",
       "         [0.6236],\n",
       "         [0.4736],\n",
       "         [0.3219]],\n",
       "\n",
       "        [[0.0247],\n",
       "         [0.4741],\n",
       "         [0.3055],\n",
       "         [0.4610],\n",
       "         [0.6170],\n",
       "         [1.0361],\n",
       "         [0.4936],\n",
       "         [0.9337],\n",
       "         [0.4075],\n",
       "         [0.6274],\n",
       "         [0.7139],\n",
       "         [0.5099],\n",
       "         [0.7977],\n",
       "         [0.5994],\n",
       "         [0.7318],\n",
       "         [0.7409]],\n",
       "\n",
       "        [[0.4339],\n",
       "         [0.9465],\n",
       "         [0.4745],\n",
       "         [0.9536],\n",
       "         [0.5034],\n",
       "         [0.6851],\n",
       "         [0.5025],\n",
       "         [0.9093],\n",
       "         [0.7315],\n",
       "         [0.6425],\n",
       "         [0.8583],\n",
       "         [0.7379],\n",
       "         [0.6940],\n",
       "         [0.6388],\n",
       "         [1.0319],\n",
       "         [0.5494]],\n",
       "\n",
       "        [[0.7721],\n",
       "         [0.5807],\n",
       "         [0.4313],\n",
       "         [0.5852],\n",
       "         [0.5470],\n",
       "         [0.5265],\n",
       "         [0.6862],\n",
       "         [0.6291],\n",
       "         [0.3460],\n",
       "         [0.6201],\n",
       "         [0.5943],\n",
       "         [0.6645],\n",
       "         [0.6703],\n",
       "         [0.5151],\n",
       "         [0.5763],\n",
       "         [0.7019]],\n",
       "\n",
       "        [[0.6690],\n",
       "         [0.2534],\n",
       "         [0.1012],\n",
       "         [0.1882],\n",
       "         [0.4721],\n",
       "         [0.4654],\n",
       "         [0.6472],\n",
       "         [0.6848],\n",
       "         [0.5177],\n",
       "         [0.6228],\n",
       "         [0.6336],\n",
       "         [0.7963],\n",
       "         [0.4765],\n",
       "         [0.7067],\n",
       "         [0.1841],\n",
       "         [0.4596]],\n",
       "\n",
       "        [[0.2312],\n",
       "         [0.4397],\n",
       "         [0.3555],\n",
       "         [0.6015],\n",
       "         [0.7507],\n",
       "         [0.2773],\n",
       "         [0.7213],\n",
       "         [0.4721],\n",
       "         [0.8238],\n",
       "         [0.6093],\n",
       "         [0.8657],\n",
       "         [0.5672],\n",
       "         [0.7893],\n",
       "         [0.5477],\n",
       "         [0.7786],\n",
       "         [0.4516]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
